{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***2023 Brain Age Predition - iFLYTEK A.I. Developer Competition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In f:\\Anaconda\\ANA\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1 Load Dataset***\n",
    "\n",
    "***This Dataset contains 12 csv files, which come from MRI scanner.***\n",
    "\n",
    "***This part aims to load the dataset and use pre-process methods to construct data features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aseg\n",
      "lh.GausCurv\n",
      "lh.GrayVol\n",
      "lh.MeanCurv\n",
      "lh.SurfArea\n",
      "lh.ThickAvg\n",
      "rh.GausCurv\n",
      "rh.GrayVol\n",
      "rh.MeanCurv\n",
      "rh.SurfArea\n",
      "rh.ThickAvg\n",
      "subject_info\n",
      "wmparc\n",
      "aseg\n",
      "lh.GausCurv\n",
      "lh.GrayVol\n",
      "lh.MeanCurv\n",
      "lh.SurfArea\n",
      "rh.GausCurv\n",
      "rh.GrayVol\n",
      "rh.MeanCurv\n",
      "rh.SurfArea\n",
      "rh.ThickAvg\n",
      "subject_info\n",
      "wmparc\n",
      "dict_keys(['aseg', 'lh.GausCurv', 'lh.GrayVol', 'lh.MeanCurv', 'lh.SurfArea', 'lh.ThickAvg', 'rh.GausCurv', 'rh.GrayVol', 'rh.MeanCurv', 'rh.SurfArea', 'rh.ThickAvg', 'subject_info', 'wmparc'])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "train_datafolder_path = 'data\\\\train'\n",
    "test_datafolder_path = 'data\\\\test'\n",
    "\n",
    "def read_datafile(datafolder_path, is_test=False):\n",
    "    feature_dict = {}\n",
    "    for file_name in os.listdir(datafolder_path):\n",
    "        data_path = os.path.join(datafolder_path, file_name)\n",
    "        feature_df = pd.read_csv(data_path)\n",
    "        feature_name = file_name[:file_name.find('-')]\n",
    "        print(feature_name)\n",
    "\n",
    "        if 'subject_info' in data_path:\n",
    "            if not is_test:\n",
    "                # get label colunm from y_dataframe\n",
    "                label_df = feature_df.iloc[:, 3]\n",
    "                feature_dict[feature_name] = label_df\n",
    "            else:\n",
    "                feature_dict[feature_name] = None\n",
    "        else:\n",
    "            # drop the label numbers of x_dataframe\n",
    "            feature_df = feature_df.iloc[:, 1:]\n",
    "            feature_dict[feature_name] = feature_df\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "train_feature_dict, test_feature_dict = read_datafile(train_datafolder_path), read_datafile(test_datafolder_path, is_test=True)\n",
    "\n",
    "print(train_feature_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use missingno to check the dataframe\n",
    "for index, name in enumerate(train_feature_dict.keys()):\n",
    "    if name != 'subject_info':\n",
    "        msno.matrix(train_feature_dict[name], figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# use seaborm to visualize the distribution\n",
    "for index, name in enumerate(train_feature_dict.keys()):\n",
    "    if name != 'subject_info':\n",
    "        sns.distplot(train_feature_dict[name], bins=100, color=\"green\") \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80438696 0.83953257 0.53569915 ... 0.67346087 0.54215385 0.77105575]\n",
      " [0.94836407 0.78379198 0.59376558 ... 0.59944348 0.53661538 0.66429419]\n",
      " [0.73413451 0.77679294 0.49010547 ... 0.70921739 0.55815385 0.86081455]\n",
      " ...\n",
      " [0.69663256 0.69873467 0.49867682 ... 0.57892174 0.48246154 0.6915777 ]\n",
      " [0.75346653 0.62082909 0.39679729 ... 0.66518261 0.648      0.8413075 ]\n",
      " [0.74340632 0.56885192 0.3168239  ... 0.54761739 0.58953846 0.63094767]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_preprocess(data_dict):\n",
    "    # Min-Max\n",
    "    for index, feature_df in enumerate(data_dict.keys()):\n",
    "        if name != 'subject_info':\n",
    "            data_dict[feature_df] = (data_dict[feature_df] - data_dict[feature_df].min()) / (data_dict[feature_df].max() - data_dict[feature_df].min())\n",
    "    return data_dict\n",
    "\n",
    "def feature_aug(data_dict):\n",
    "\n",
    "    return None\n",
    "\n",
    "def feature_combination(data_dict):\n",
    "\n",
    "    original_x_thick = (data_dict['lh.ThickAvg'] + data_dict['rh.ThickAvg']) * 0.5\n",
    "    original_x_gauscurv = (data_dict['lh.GausCurv'] + data_dict['rh.GausCurv']) * 0.5\n",
    "    original_x_meancurv = (data_dict['lh.MeanCurv'] + data_dict['rh.MeanCurv']) * 0.5\n",
    "    original_x_surfarea = (data_dict['lh.SurfArea'] + data_dict['rh.SurfArea']) * 0.5\n",
    "    original_x_grayvol = (data_dict['lh.GrayVol'] + data_dict['rh.GrayVol']) * 0.5\n",
    "    original_x_wmparc = data_dict['wmparc']\n",
    "    original_x_aseg = data_dict['aseg']\n",
    "\n",
    "    original_x = np.hstack(\n",
    "        [original_x_thick, original_x_gauscurv, original_x_meancurv, original_x_surfarea, original_x_grayvol, original_x_wmparc, original_x_aseg, \n",
    "         data_dict['lh.ThickAvg'], data_dict['rh.ThickAvg'], data_dict['lh.GausCurv'], data_dict['rh.GausCurv'], data_dict['lh.MeanCurv'],\n",
    "         data_dict['rh.MeanCurv'], data_dict['lh.SurfArea'], data_dict['rh.SurfArea'], data_dict['lh.GrayVol'], data_dict['rh.GrayVol']])\n",
    "    \n",
    "    return original_x\n",
    "\n",
    "original_x = feature_combination(data_preprocess(train_feature_dict))\n",
    "print(original_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***2 Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from RVM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 将数据集分为训练集和测试集\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_original_x, train_original_y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_original_x = torch.tensor(test_original_x, dtype=torch.float32)\n",
    "\n",
    "# RVR\n",
    "print('\\n RVR Model')\n",
    "\n",
    "linear_model = RVR(kernel=\"linear\")\n",
    "linear_model.fit(X_train, y_train)\n",
    "linear_model_valid_prediction = linear_model.predict(X_valid)\n",
    "print('\\nVALID MAE:{}'.format(mean_absolute_error(y_valid, [int(i) for i in linear_model_valid_prediction])))\n",
    "print('VALID Variance {}'.format(np.var([int(i) for i in linear_model_valid_prediction])))\n",
    "linear_model_test_prediction = linear_model.predict(test_original_x)\n",
    "print([int(i) for i in linear_model_test_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in linear_model_test_prediction])))\n",
    "\n",
    "rbf_model = RVR(kernel=\"rbf\")\n",
    "rbf_model.fit(X_train, y_train)\n",
    "rbf_model_valid_prediction = rbf_model.predict(X_valid)\n",
    "print('\\nVALID MAE:{}'.format(mean_absolute_error(y_valid, [int(i) for i in rbf_model_valid_prediction])))\n",
    "print('VALID Variance {}'.format(np.var([int(i) for i in rbf_model_valid_prediction])))\n",
    "rbf_model_test_prediction = rbf_model.predict(test_original_x)\n",
    "print([int(i) for i in rbf_model_test_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in rbf_model_test_prediction])))\n",
    "\n",
    "poly_model = RVR(kernel=\"poly\")\n",
    "poly_model.fit(X_train, y_train)\n",
    "poly_model_valid_prediction = poly_model.predict(X_valid)\n",
    "print('\\nVALID MAE:{}'.format(mean_absolute_error(y_valid, [int(i) for i in poly_model_valid_prediction])))\n",
    "print('VALID Variance {}'.format(np.var([int(i) for i in poly_model_valid_prediction])))\n",
    "poly_model_test_prediction = rbf_model.predict(test_original_x)\n",
    "print([int(i) for i in poly_model_test_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in poly_model_test_prediction])))\n",
    "\n",
    "# 随机森林\n",
    "print('\\n RandomForest Model')\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=12, random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_model_valid_prediction = rf_model.predict(X_valid)\n",
    "print('\\nVALID MAE:{}'.format(mean_absolute_error(y_valid, [int(i) for i in rf_model_valid_prediction])))\n",
    "print('VALID Variance {}'.format(np.var([int(i) for i in rf_model_valid_prediction])))\n",
    "rf_model_test_prediction = rf_model.predict(test_original_x)\n",
    "print([int(i) for i in rf_model_test_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in rf_model_test_prediction])))\n",
    "\n",
    "# Bagging\n",
    "print('\\n Bagging Model')\n",
    "\n",
    "bag_model = BaggingRegressor()\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_model_valid_prediction = bag_model.predict(X_valid)\n",
    "print('\\nVALID MAE:{}'.format(mean_absolute_error(y_valid, [int(i) for i in bag_model_valid_prediction])))\n",
    "print('VALID Variance {}'.format(np.var([int(i) for i in bag_model_valid_prediction])))\n",
    "bag_model_test_prediction = bag_model.predict(test_original_x)\n",
    "print([int(i) for i in bag_model_test_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in bag_model_test_prediction])))\n",
    "\n",
    "# XGBoost\n",
    "print('\\n XGBoost Model')\n",
    "\n",
    "xgb_model = XGBRegressor(learning_rate=0.2)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_model_valid_prediction = xgb_model.predict(X_valid)\n",
    "print('\\nVALID MAE:{}'.format(mean_absolute_error(y_valid, [int(i) for i in xgb_model_valid_prediction])))\n",
    "print('LABEL Variance {}'.format(np.var([int(i) for i in y_valid])))\n",
    "print('VALID Variance {}'.format(np.var([int(i) for i in xgb_model_valid_prediction])))\n",
    "xgb_model_test_prediction = xgb_model.predict(test_original_x)\n",
    "print([int(i) for i in xgb_model_test_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in xgb_model_test_prediction])))\n",
    "\n",
    "# LightGBM\n",
    "print('\\n LightGBM Model')\n",
    "\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "lgbm_model_valid_prediction = lgbm_model.predict(X_valid)\n",
    "print('\\nVALID MAE:{}'.format(mean_absolute_error(y_valid, [int(i) for i in lgbm_model_valid_prediction])))\n",
    "print('LABEL Variance {}'.format(np.var([int(i) for i in y_valid])))\n",
    "print('VALID Variance {}'.format(np.var([int(i) for i in lgbm_model_valid_prediction])))\n",
    "lgbm_model_test_prediction = lgbm_model.predict(test_original_x)\n",
    "print([int(i) for i in lgbm_model_test_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in lgbm_model_test_prediction])))\n",
    "\n",
    "# 集成模型\n",
    "print('\\n Ensemble Model')\n",
    "\n",
    "new_linear_pred, new_rbf_pred, new_poly_pred = [int(i) for i in linear_model_valid_prediction], [int(i) for i in rbf_model_valid_prediction], [int(i) for i in poly_model_valid_prediction]\n",
    "new_rf_pred = [int(i) for i in rf_model_valid_prediction]\n",
    "new_bag_pred = [int(i) for i in bag_model_valid_prediction]\n",
    "new_xgb_pred = [int(i) for i in xgb_model_valid_prediction]\n",
    "new_lgbm_pred = [int(i) for i in lgbm_model_valid_prediction]\n",
    "\n",
    "# ensemble_prediction = [(i + j) / 2 for i, j in zip(new_rf_pred, new_rbf_pred)]\n",
    "ensemble_prediction = [(i + j + k) / 3 for i, j, k in zip(new_xgb_pred, new_bag_pred, new_linear_pred)]\n",
    "print('\\nENSEMBLE VALID MAE:{}'.format(mean_absolute_error(y_valid, ensemble_prediction)))\n",
    "print('ENSEMBLE VALID Variance {}'.format(np.var([int(i) for i in ensemble_prediction])))\n",
    "\n",
    "test_new_linear_pred, test_new_rbf_pred, test_new_poly_pred = [int(i) for i in linear_model_test_prediction], [\n",
    "    int(i) for i in rbf_model_test_prediction], [int(i) for i in poly_model_test_prediction]\n",
    "test_new_bag_pred = [int(i) for i in bag_model_test_prediction]\n",
    "test_new_rf_pred = [int(i) for i in rf_model_test_prediction]\n",
    "test_new_xgb_pref = [int(i) for i in xgb_model_test_prediction]\n",
    "\n",
    "# test_ensemble_prediction = [(i + j) / 2 for i, j in zip(test_new_rf_pred, test_new_rbf_pred)]\n",
    "test_ensemble_prediction = [(i + j + k) / 3 for i, j, k in\n",
    "                            zip(test_new_xgb_pref, test_new_bag_pred, test_new_linear_pred)]\n",
    "print([int(i) for i in test_ensemble_prediction])\n",
    "print('TEST Variance {}'.format(np.var([int(i) for i in test_ensemble_prediction])))\n",
    "\n",
    "# 写结果\n",
    "# final_list = [int(i) for i in [int(i) for i in lgbm_model_test_prediction]]\n",
    "# submission_version_name = 'Ensemble-DataAug3-XGBoost_Bagging_RVR'\n",
    "# write_submission(final_list, submission_version_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
